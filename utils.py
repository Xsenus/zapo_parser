from threading import Lock
import os
import random
import re
from typing import Callable, Tuple
import requests
from concurrent.futures import ThreadPoolExecutor

__all__ = [
    "proxy_lock",
    "load_proxies",
    "download_proxies",
    "get_proxy_dict",
    "fetch_with_proxies",
    "MIRRORS",
    "with_mirror",
]

# üîí –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–∫ –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–∫—Å–∏
proxy_lock = Lock()

# üîó –®–∞–±–ª–æ–Ω URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ SOCKS5 –ø—Ä–æ–∫—Å–∏ —Å best-proxies.ru
PROXY_API_URL = (
    "https://api.best-proxies.ru/proxylist.txt"
    "?key={key}&type=socks5&level=1&speed=1&limit=0"
)

def download_proxies(api_key: str) -> list[str]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ SOCKS5-–ø—Ä–æ–∫—Å–∏ –ø–æ API-–∫–ª—é—á—É —Å best-proxies.ru."""
    try:
        response = requests.get(PROXY_API_URL.format(key=api_key), timeout=10)
        response.raise_for_status()
        return [line.strip() for line in response.text.splitlines() if line.strip()]
    except Exception:
        return []

def check_proxy_alive(proxy: str, timeout: int = 5) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –ø—Ä–æ–∫—Å–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—Ä–æ—Å –∫ Google."""
    test_url = "https://www.google.com"
    try:
        response = requests.get(
            test_url,
            proxies=get_proxy_dict(proxy),
            timeout=timeout
        )
        return response.ok
    except Exception:
        return False

def filter_alive_proxies(proxies: list[str], threads: int = 50) -> list[str]:
    """–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ (–º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ)."""
    with ThreadPoolExecutor(max_workers=threads) as executor:
        results = list(executor.map(check_proxy_alive, proxies))
    return [proxy for proxy, ok in zip(proxies, results) if ok]

def load_proxies(
    proxy_file: str,
    alive_file: str | None = None,
    *,
    api_key: str | None = None,
    logger: Callable[[str], None] | None = None,
    check_alive: bool = False,
) -> list[str]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–∫—Å–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º API.
    –ü—Ä–∏ check_alive=True ‚Äî –æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ alive_file.
    """
    proxies: set[str] = set()
    api_key = api_key or os.getenv("PROXY_API_KEY")

    # üîÅ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É —Å API
    if api_key:
        api_proxies = download_proxies(api_key)
        if api_proxies:
            proxies.update(api_proxies)
            # üìÅ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if os.path.exists(proxy_file):
                with open(proxy_file, "r", encoding="utf-8") as f:
                    proxies.update(line.strip() for line in f if line.strip())

            proxies = sorted(proxies)

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∂–∏–≤–æ—Å—Ç—å, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            if check_alive:
                if logger:
                    logger(f"[PROXIES] üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ {len(proxies)} –ø—Ä–æ–∫—Å–∏...")
                alive = filter_alive_proxies(proxies)
                if logger:
                    logger(f"[PROXIES] ‚úÖ –ñ–∏–≤—ã—Ö: {len(alive)}")

                if alive_file:
                    with open(alive_file, "w", encoding="utf-8") as f:
                        f.write("\n".join(alive))
                return alive

            # üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ –ø—Ä–æ–∫—Å–∏
            with open(proxy_file, "w", encoding="utf-8") as f:
                f.write("\n".join(proxies))
            if logger:
                logger(f"[PROXIES] –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å API ({len(api_proxies)} –Ω–æ–≤—ã—Ö), –≤—Å–µ–≥–æ: {len(proxies)}")
            return list(proxies)

    # üìÇ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å alive-—Ñ–∞–π–ª
    if alive_file and os.path.exists(alive_file):
        with open(alive_file, "r", encoding="utf-8") as f:
            proxies = {line.strip() for line in f if line.strip()}
        if proxies:
            if logger:
                logger(f"[PROXIES] –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ alive-—Ñ–∞–π–ª–∞: {len(proxies)}")
            return list(proxies)

    # üìÇ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
    if os.path.exists(proxy_file):
        with open(proxy_file, "r", encoding="utf-8") as f:
            proxies = {line.strip() for line in f if line.strip()}
        if proxies:
            if check_alive:
                if logger:
                    logger(f"[PROXIES] üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ {len(proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ proxy-—Ñ–∞–π–ª–∞...")
                alive = filter_alive_proxies(list(proxies))
                if logger:
                    logger(f"[PROXIES] ‚úÖ –ñ–∏–≤—ã—Ö: {len(alive)}")
                if alive_file:
                    with open(alive_file, "w", encoding="utf-8") as f:
                        f.write("\n".join(alive))
                return alive

            if logger:
                logger(f"[PROXIES] –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ proxy-—Ñ–∞–π–ª–∞: {len(proxies)}")
            return list(proxies)

    if logger:
        logger("[PROXIES] ‚ùå –ü—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî –Ω–∏ API, –Ω–∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã.")
    return []

def get_proxy_dict(proxy: str) -> dict:
    """–í–µ—Ä–Ω—É—Ç—å —Å–ª–æ–≤–∞—Ä—å –ø—Ä–æ–∫—Å–∏ –¥–ª—è requests —Å SOCKS5."""
    return {"http": f"socks5h://{proxy}", "https": f"socks5h://{proxy}"}

# üîÅ –°–ø–∏—Å–æ–∫ –∑–µ—Ä–∫–∞–ª –¥–ª—è –æ–±—Ö–æ–¥–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
MIRRORS = [
    "https://part.avtomir.ru",
    "https://zapo.ru",
    "https://vindoc.ru",
    "https://autona88.ru",
    "https://b2b.autorus.ru",
    "https://xxauto.pro",
    "https://motexc.ru",
]

def with_mirror(url: str, mirror: str) -> str:
    """–ó–∞–º–µ–Ω–∏—Ç—å –¥–æ–º–µ–Ω –≤ URL –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π mirror."""
    return re.sub(r"https://[^/]+", mirror, url)

def fetch_with_proxies(
    url: str,
    proxies: list[str],
    working: list[str] | None = None,
    *,
    headers: dict | None = None,
    retries: int = 3,
    timeout: int = 10,
    logger: Callable[[str], None] | None = None,
    reload_proxies: Callable[[], list[str]] | None = None,
) -> Tuple[str | None, str | None]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏. –ü—Ä–∏ —É–¥–∞—á–Ω–æ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏
    –ø—Ä–æ–∫—Å–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ working –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    –ü—Ä–∏ –Ω–µ—É–¥–∞—á–µ ‚Äî –ø—Ä–æ–∫—Å–∏ –∏—Å–∫–ª—é—á–∞–µ—Ç—Å—è –∏–∑ —Å–ø–∏—Å–∫–∞. –í–æ–∑–º–æ–∂–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    —Å–ø–∏—Å–∫–∞ —á–µ—Ä–µ–∑ reload_proxies().
    """
    working = working or []

    for attempt in range(1, retries + 1):
        with proxy_lock:
            proxy_list = working + [p for p in proxies if p not in working]
            random.shuffle(proxy_list[len(working):])

        while proxy_list:
            proxy = proxy_list.pop(0)
            try:
                response = requests.get(
                    url,
                    headers=headers,
                    timeout=timeout,
                    proxies=get_proxy_dict(proxy),
                )
                response.raise_for_status()
                with proxy_lock:
                    if proxy in working:
                        working.remove(proxy)
                    working.insert(0, proxy)
                return response.text, proxy
            except Exception as e:
                if logger:
                    logger(f"[–ü–†–û–ö–°–ò –û–®–ò–ë–ö–ê] {proxy} ‚Äî {e}")
                with proxy_lock:
                    if proxy in proxies:
                        proxies.remove(proxy)

        if reload_proxies and attempt < retries:
            if logger:
                logger("[–ü–†–û–ö–°–ò] üîÅ –í—Å–µ –ø—Ä–æ–∫—Å–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–µ...")
            with proxy_lock:
                new_proxies = reload_proxies()
                if new_proxies:
                    if logger:
                        logger(f"[–ü–†–û–ö–°–ò] –ü–æ–ª—É—á–µ–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–æ–∫—Å–∏: {len(new_proxies)}")
                    proxies.clear()
                    proxies.extend(new_proxies)
                    continue
                else:
                    if logger:
                        logger("[–ü–†–û–ö–°–ò] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–æ–∫—Å–∏.")
                    break

        # üì° –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ ‚Äî –±–µ–∑ –ø—Ä–æ–∫—Å–∏
        try:
            if logger:
                logger(f"[–ü–û–ü–´–¢–ö–ê {attempt}] –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
            response = requests.get(url, headers=headers, timeout=timeout)
            response.raise_for_status()
            return response.text, None
        except Exception as e:
            if logger:
                logger(f"[–û–®–ò–ë–ö–ê] –ü–æ–ø—ã—Ç–∫–∞ {attempt} –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")

    if logger:
        logger(f"[–û–®–ò–ë–ö–ê] ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã: {url}")
    return None, None